{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.pardir)\n",
    "from utils.mixins import NNMixin, TrainMixin\n",
    "from utils import ymr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Model Hyperparameters\n",
    "SENTENCE_LENGTH_PADDED = 64\n",
    "HIDDEN_DIM = 200\n",
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "# Training parameters\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "EVALUATE_EVERY = 16\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train/dev/test size: 29017/1528/7637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, dev_x, dev_y, test_x, test_y = ymr_data.generate_dataset(fixed_length=SENTENCE_LENGTH_PADDED)\n",
    "VOCABULARY_SIZE = max(train_x.max(), dev_x.max(), test_x.max()) + 1\n",
    "print(\"\\ntrain/dev/test size: {:d}/{:d}/{:d}\\n\".format(len(train_y), len(dev_y), len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CharRNN(object, NNMixin, TrainMixin):\n",
    "    \n",
    "    def __init__(self, vocabulary_size, sequence_length, batch_size, num_classes,\n",
    "                 embedding_size=128, hidden_dim=256,num_gpus=1, cell=None, loss=\"linear_gain\"):\n",
    "        \n",
    "        self.input_x = tf.placeholder(tf.int32, [batch_size, sequence_length])\n",
    "        self.input_y = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "        \n",
    "        if not cell:\n",
    "            self.cell = rnn_cell.LSTMCell(hidden_dim, embedding_size, use_peepholes=True)\n",
    "        \n",
    "        with tf.variable_scope(\"embedding\"):\n",
    "            self.embedded_chars = self._build_embedding([vocabulary_size, embedding_size], self.input_x)\n",
    "        \n",
    "        with tf.variable_scope(\"rnn\") as scope:\n",
    "            self.state = tf.Variable(tf.zeros([batch_size, self.cell.state_size]))\n",
    "            self.outputs = []\n",
    "            self.states = [self.state]\n",
    "            for i in range(sequence_length):\n",
    "                if i > 0:\n",
    "                    scope.reuse_variables()\n",
    "                new_output, new_state = self.cell(self.embedded_chars[:, i, :], self.states[-1])\n",
    "                self.outputs.append(new_output)\n",
    "                self.states.append(new_state)\n",
    "                \n",
    "            self.final_state = self.states[-1]\n",
    "            self.final_output = self.outputs[-1]\n",
    "        \n",
    "        with tf.variable_scope(\"softmax\"):\n",
    "            self.ys = [self._build_softmax([hidden_dim, num_classes], o) for o in self.outputs]\n",
    "            self.y = self.ys[-1]\n",
    "        \n",
    "        if loss == \"linear_gain\":\n",
    "             # Loss with linear gain. We output at each time step and multiply losses with a linspace\n",
    "            packed_ys = tf.pack(self.ys)\n",
    "            tiled_labels = tf.pack([self.input_y for i in range(sequence_length)])\n",
    "            accumulated_losses = -tf.reduce_sum(tiled_labels * tf.log(packed_ys), [1,2])\n",
    "            loss_gains = tf.linspace(0.0, 1.0, sequence_length)\n",
    "            annealed_losses = tf.mul(loss_gains, tf.concat(0, accumulated_losses))\n",
    "            accumulated_loss = tf.reduce_sum(annealed_losses)\n",
    "            self.loss = accumulated_loss\n",
    "            self.mean_loss = tf.reduce_mean(annealed_losses)\n",
    "        elif loss == \"last\":        \n",
    "            # Standard loss, only last output is considered\n",
    "            self.loss = self._build_total_ce_loss(self.ys[-1], self.input_y)\n",
    "            self._build_mean_ce_loss(self.ys[-1], self.input_y)\n",
    "\n",
    "        # Summaries\n",
    "        total_loss_summary = tf.scalar_summary(\"total loss\", self.loss)\n",
    "        mean_loss_summary = tf.scalar_summary(\"mean loss\", self.mean_loss)\n",
    "        accuracy_summmary = tf.scalar_summary(\"accuracy\", self._build_accuracy(self.y, self.input_y))\n",
    "        self.summaries = tf.merge_all_summaries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 128) for Tensor u'Placeholder:0', which has shape (Dimension(64), Dimension(64))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-a92313e0a664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mEVALUATE_EVERY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/nlp/sentiment-analysis/utils/mixins.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(feed_dict)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# Execute train step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;31m# Print Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mtime_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dennybritz/projects/python-venvs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    339\u001b[0m                   \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                   % (np_val.shape, subfeed_t.name,\n\u001b[0;32m--> 341\u001b[0;31m                      tuple(subfeed_t.get_shape().dims)))\n\u001b[0m\u001b[1;32m    342\u001b[0m           \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (64, 128) for Tensor u'Placeholder:0', which has shape (Dimension(64), Dimension(64))"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(allow_soft_placement=True)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Instantiate our model\n",
    "        rnn = CharRNN(VOCABULARY_SIZE, SENTENCE_LENGTH_PADDED, BATCH_SIZE, 2)\n",
    "\n",
    "        # Generate input batches (using tensorflow)\n",
    "        with tf.variable_scope(\"input\"):\n",
    "            placeholder_x = tf.placeholder(tf.int32, train_x.shape)\n",
    "            placeholder_y = tf.placeholder(tf.float32, train_y.shape)\n",
    "            train_x_var = tf.Variable(placeholder_x, trainable=False, collections=[])\n",
    "            train_y_var = tf.Variable(placeholder_y, trainable=False, collections=[])\n",
    "            x_slice, y_slice = tf.train.slice_input_producer([train_x_var, train_y_var], num_epochs=NUM_EPOCHS)\n",
    "            x_batch, y_batch = tf.train.batch([x_slice, y_slice], batch_size=BATCH_SIZE)\n",
    "\n",
    "        # Define Training procedure\n",
    "        out_dir = os.path.join(os.path.curdir, \"runs\", str(int(time.time())))\n",
    "        global_step = tf.Variable(0, name=\"global_step\")\n",
    "        optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "        # Clip the gradients\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(rnn.loss, tvars), 5)\n",
    "        train_op = optimizer.apply_gradients(zip(grads, tvars), global_step=global_step)\n",
    "        \n",
    "        # Generate train and eval seps\n",
    "        train_step = rnn.build_train_step(out_dir, train_op, global_step, rnn.summaries, save_every=8, sess=sess)\n",
    "        eval_step = rnn.build_eval_step(out_dir, global_step, rnn.summaries, sess=sess)\n",
    "\n",
    "        # Initialize variables and input data\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        sess.run([train_x_var.initializer, train_y_var.initializer], {placeholder_x: train_x, placeholder_y: train_y})\n",
    "\n",
    "        # Initialize queues\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        # Print model parameters\n",
    "        # rnn.print_parameters()\n",
    "\n",
    "        # Repeat until we're done (the input queue throws an error)...\n",
    "        try:\n",
    "            while not coord.should_stop():\n",
    "                train_step({rnn.input_x: x_batch.eval(), rnn.input_y: y_batch.eval()})\n",
    "                if global_step.eval() % EVALUATE_EVERY == 0:\n",
    "                    eval_step({rnn.input_x: dev_x[:BATCH_SIZE], rnn.input_y: dev_y[:BATCH_SIZE]})\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"Yay, training done!\")\n",
    "            eval_step({rnn.input_x: dev_x, rnn.input_y: dev_y})\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
